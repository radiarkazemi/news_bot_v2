
# scripts/benchmark_detection.py
"""
Benchmark script for news detection performance.
"""
import time
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.services.news_detector import NewsDetector
from src.services.news_filter import NewsFilter


# Sample news texts for benchmarking
BENCHMARK_TEXTS = [
    """ÙÙˆØ±ÛŒ: Ø­Ù…Ù„Ù‡ Ù…ÙˆØ´Ú©ÛŒ Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„ Ø¨Ù‡ Ù…ÙˆØ§Ø¶Ø¹ Ø§ÛŒØ±Ø§Ù† Ø¯Ø± Ø³ÙˆØ±ÛŒÙ‡ - Ø¨Ø± Ø§Ø³Ø§Ø³ Ú¯Ø²Ø§Ø±Ø´ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ù„ÛŒØŒ Ø¬Ù†Ú¯Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„ÛŒ Ú†Ù†Ø¯ÛŒÙ† Ù…ÙˆØ´Ú© Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø¸Ø§Ù…ÛŒ Ø§ÛŒØ±Ø§Ù† Ø¯Ø± Ø­ÙˆÙ…Ù‡ Ø¯Ù…Ø´Ù‚ Ø´Ù„ÛŒÚ© Ú©Ø±Ø¯Ù†Ø¯. Ø§ÛŒÙ† Ø­Ù…Ù„Ù‡ Ø¯Ø± Ù¾ÛŒ ØªÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ± Ø¨ÛŒÙ† Ø¯Ùˆ Ú©Ø´ÙˆØ± ØµÙˆØ±Øª Ú¯Ø±ÙØªÙ‡ Ø§Ø³Øª.""",
    
    """ØªØ­Ø±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¢Ù…Ø±ÛŒÚ©Ø§ Ø¹Ù„ÛŒÙ‡ Ø§ÛŒØ±Ø§Ù† Ø§Ø¹Ù„Ø§Ù… Ø´Ø¯ - ÙˆØ²Ø§Ø±Øª Ø®Ø²Ø§Ù†Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ø¢Ù…Ø±ÛŒÚ©Ø§ ÙÙ‡Ø±Ø³Øª Ø¬Ø¯ÛŒØ¯ÛŒ Ø§Ø² ØªØ­Ø±ÛŒÙ…â€ŒÙ‡Ø§ Ø¹Ù„ÛŒÙ‡ Ø¨Ø®Ø´ Ù†ÙØª Ùˆ Ú¯Ø§Ø² Ø§ÛŒØ±Ø§Ù† Ø§Ø¹Ù„Ø§Ù… Ú©Ø±Ø¯ Ú©Ù‡ Ù‚ÛŒÙ…Øª Ù†ÙØª Ø¯Ø± Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ Ø±Ø§ ØªØ­Øª ØªØ£Ø«ÛŒØ± Ù‚Ø±Ø§Ø± Ø®ÙˆØ§Ù‡Ø¯ Ø¯Ø§Ø¯.""",
    
    """Ù‚ÛŒÙ…Øª Ø·Ù„Ø§ Ø¨Ø§ ØªÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ú˜Ø¦ÙˆÙ¾Ù„ÛŒØªÛŒÚ© Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ÙØª - Ø§ÙˆÙ†Ø³ Ø·Ù„Ø§ Ø¯Ø± Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ Ø¨Ø§ Ø§ÙØ²Ø§ÛŒØ´ ØªÙ†Ø´â€ŒÙ‡Ø§ Ø¯Ø± Ø®Ø§ÙˆØ±Ù…ÛŒØ§Ù†Ù‡ Ùˆ Ø§Ø­ØªÙ…Ø§Ù„ Ø¯Ø±Ú¯ÛŒØ±ÛŒ Ù†Ø¸Ø§Ù…ÛŒ Ø¨ÛŒÙ† Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„ Ùˆ Ø§ÛŒØ±Ø§Ù† Ø¨Ù‡ Û²Û±Û°Û° Ø¯Ù„Ø§Ø± Ø±Ø³ÛŒØ¯.""",
    
    """Ù†ØªØ§Ù†ÛŒØ§Ù‡Ùˆ: Ø¢Ù…Ø§Ø¯Ù‡ Ø­Ù…Ù„Ù‡ Ø¨Ù‡ ØªØ§Ø³ÛŒØ³Ø§Øª Ù‡Ø³ØªÙ‡â€ŒØ§ÛŒ Ø§ÛŒØ±Ø§Ù† Ù‡Ø³ØªÛŒÙ… - Ù†Ø®Ø³Øª ÙˆØ²ÛŒØ± Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„ Ø¯Ø± Ú©Ù†ÙØ±Ø§Ù†Ø³ Ø®Ø¨Ø±ÛŒ Ú¯ÙØª Ú©Ù‡ Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„ ØªÙ…Ø§Ù… Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø³ØªÛŒØ§Ø¨ÛŒ Ø§ÛŒØ±Ø§Ù† Ø¨Ù‡ Ø³Ù„Ø§Ø­ Ù‡Ø³ØªÙ‡â€ŒØ§ÛŒ Ø±ÙˆÛŒ Ù…ÛŒØ² Ø¯Ø§Ø±Ø¯.""",
    
    """Ø¨Ø§Ø²Ø§Ø± Ø§Ø±Ø² Ø¨Ø§ Ø§Ø®Ø¨Ø§Ø± Ø¬Ù†Ú¯ Ø¯Ú†Ø§Ø± Ù†ÙˆØ³Ø§Ù† Ø´Ø¯ - Ø¯Ù„Ø§Ø± Ø¯Ø± Ø¨Ø§Ø²Ø§Ø± ØªÙ‡Ø±Ø§Ù† Ù¾Ø³ Ø§Ø² Ø§Ù†ØªØ´Ø§Ø± Ø§Ø®Ø¨Ø§Ø± Ø§Ø­ØªÙ…Ø§Ù„ Ø¯Ø±Ú¯ÛŒØ±ÛŒ Ù†Ø¸Ø§Ù…ÛŒ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡ Ø¨Ø§ Ø¬Ù‡Ø´ Û²Û°Û° ØªÙˆÙ…Ø§Ù†ÛŒ Ø±ÙˆØ¨Ø±Ùˆ Ø´Ø¯ Ùˆ Ø¨Ù‡ Û¶Û¸ Ù‡Ø²Ø§Ø± ØªÙˆÙ…Ø§Ù† Ø±Ø³ÛŒØ¯.""",
]


def benchmark_detection_speed():
    """Benchmark news detection speed."""
    print("âš¡ Benchmarking News Detection Speed")
    print("-" * 40)
    
    detector = NewsDetector()
    
    # Warm up
    for text in BENCHMARK_TEXTS[:2]:
        detector.is_news(text)
    
    # Benchmark detection
    start_time = time.time()
    iterations = 1000
    
    for i in range(iterations):
        for text in BENCHMARK_TEXTS:
            detector.is_news(text)
    
    end_time = time.time()
    total_time = end_time - start_time
    avg_time_per_detection = (total_time / (iterations * len(BENCHMARK_TEXTS))) * 1000
    
    print(f"Total detections: {iterations * len(BENCHMARK_TEXTS)}")
    print(f"Total time: {total_time:.2f} seconds")
    print(f"Average per detection: {avg_time_per_detection:.2f} ms")
    print(f"Detections per second: {(iterations * len(BENCHMARK_TEXTS)) / total_time:.0f}")


def benchmark_filtering_speed():
    """Benchmark news filtering speed."""
    print("\nâš¡ Benchmarking News Filtering Speed")
    print("-" * 40)
    
    # Warm up
    for text in BENCHMARK_TEXTS[:2]:
        NewsFilter.is_relevant_news(text)
    
    # Benchmark filtering
    start_time = time.time()
    iterations = 1000
    
    for i in range(iterations):
        for text in BENCHMARK_TEXTS:
            NewsFilter.is_relevant_news(text)
    
    end_time = time.time()
    total_time = end_time - start_time
    avg_time_per_filter = (total_time / (iterations * len(BENCHMARK_TEXTS))) * 1000
    
    print(f"Total filterings: {iterations * len(BENCHMARK_TEXTS)}")
    print(f"Total time: {total_time:.2f} seconds")
    print(f"Average per filtering: {avg_time_per_filter:.2f} ms")
    print(f"Filterings per second: {(iterations * len(BENCHMARK_TEXTS)) / total_time:.0f}")


def benchmark_text_cleaning():
    """Benchmark text cleaning speed."""
    print("\nâš¡ Benchmarking Text Cleaning Speed")
    print("-" * 40)
    
    detector = NewsDetector()
    
    # Warm up
    for text in BENCHMARK_TEXTS[:2]:
        detector.clean_news_text(text)
    
    # Benchmark cleaning
    start_time = time.time()
    iterations = 1000
    
    for i in range(iterations):
        for text in BENCHMARK_TEXTS:
            detector.clean_news_text(text)
    
    end_time = time.time()
    total_time = end_time - start_time
    avg_time_per_clean = (total_time / (iterations * len(BENCHMARK_TEXTS))) * 1000
    
    print(f"Total cleanings: {iterations * len(BENCHMARK_TEXTS)}")
    print(f"Total time: {total_time:.2f} seconds")
    print(f"Average per cleaning: {avg_time_per_clean:.2f} ms")
    print(f"Cleanings per second: {(iterations * len(BENCHMARK_TEXTS)) / total_time:.0f}")


def test_accuracy():
    """Test detection and filtering accuracy."""
    print("\nğŸ¯ Testing Detection Accuracy")
    print("-" * 40)
    
    detector = NewsDetector()
    
    # All benchmark texts should be detected as news
    correct_detections = 0
    for text in BENCHMARK_TEXTS:
        if detector.is_news(text):
            correct_detections += 1
    
    detection_accuracy = (correct_detections / len(BENCHMARK_TEXTS)) * 100
    print(f"News detection accuracy: {detection_accuracy:.1f}% ({correct_detections}/{len(BENCHMARK_TEXTS)})")
    
    # All benchmark texts should be relevant
    relevant_detections = 0
    for text in BENCHMARK_TEXTS:
        is_relevant, score, topics = NewsFilter.is_relevant_news(text)
        if is_relevant:
            relevant_detections += 1
    
    relevance_accuracy = (relevant_detections / len(BENCHMARK_TEXTS)) * 100
    print(f"Relevance filtering accuracy: {relevance_accuracy:.1f}% ({relevant_detections}/{len(BENCHMARK_TEXTS)})")


def main():
    """Main benchmark function."""
    print("ğŸ News Detector Performance Benchmark")
    print("=" * 50)
    
    benchmark_detection_speed()
    benchmark_filtering_speed()
    benchmark_text_cleaning()
    test_accuracy()
    
    print("\nâœ… Benchmark complete!")


if __name__ == "__main__":
    main()